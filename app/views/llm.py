import streamlit as st
import os
import sys
import datetime

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.speech_to_text import WhisperLiveTranscription

# Instanciation du transcripteur
transcriber = WhisperLiveTranscription(
    model_id="openai/whisper-small", language="french"
)


def llm_page():
    st.title("Requ√™te du mod√®le")
    st.subheader("Interrogez le LLM via votre voix ou texte")

    # Initialisation de l'√©tat de session
    if "recording" not in st.session_state:
        st.session_state.recording = False
    if "transcription" not in st.session_state:
        st.session_state.transcription = ""

    # Contr√¥les d'enregistrement
    col1, col2 = st.columns(2)

    if col1.button("üé§ D√©marrer l'enregistrement"):
        st.session_state.recording = True

        # Cr√©ation du fichier o√π les transcriptions seront stock√©es
        # timestamp YYYYMMDD_HHMM :
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
        # Cr√©er le fichier texte vide avec son timestamp
        with open(f"transcription_{timestamp}.txt", "a"):
            pass
            # on ira ensuite le remplir via speech_to_text.py

        transcriber.start_recording()
        st.info("Enregistrement en cours...")

    if col2.button("‚èπÔ∏è Arr√™ter l'enregistrement"):
        if st.session_state.recording:
            st.session_state.recording = False
            transcriber.stop_recording()
            st.success("Enregistrement termin√©")

            # V√©rifier si une transcription a √©t√© trouv√©e
            # if st.session_state.final_transcription:
            #     st.session_state.transcription = st.session_state.final_transcription
            #     st.write(f"Transcription : {st.session_state.final_transcription}")
            #     print(
            #         f"DEBUG: Displaying transcription: {st.session_state.final_transcription}"
            #     )
            # else:
            #     st.warning("Aucune transcription trouv√©e")
            #     print("DEBUG: No transcription found to display")

    # Affichage de la transcription
    # if st.session_state.transcription:
    #     text_query = st.session_state.transcription
    #     st.write(f"Transcription : {text_query}")
    # else:
    #     text_query = st.text_input("Ou entrez votre question ici :")

    # # Upload audio ou entr√©e texte
    # audio_file = st.file_uploader("T√©l√©versez un fichier audio", type=["wav", "mp3"])
    # if audio_file:
    #     text_query = WhisperLiveTranscription._transcribe_audio(
    #         audio_file
    #     )  # Intercaler ici le mod√®le speech to text
    #     st.write(f"Transcription : {text_query}")
    # else:
    #     text_query = st.text_input("Ou entrez votre question ici :")

    # R√©sultat du LLM
    if st.button("Soumettre"):
        # Appeler votre LLM ici
        response = (
            f"R√©ponse simul√©e pour : {text_query}"  # Remplacer par un appel au LLM
        )
        st.write("R√©ponse du LLM :", response)
